[
  {
    "objectID": "python_basics.html",
    "href": "python_basics.html",
    "title": "Introduction to Python",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')"
  },
  {
    "objectID": "python_basics.html#what-is-python",
    "href": "python_basics.html#what-is-python",
    "title": "Introduction to Python",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')"
  },
  {
    "objectID": "python_basics.html#variables-and-data-types",
    "href": "python_basics.html#variables-and-data-types",
    "title": "Introduction to Python",
    "section": "Variables and Data Types",
    "text": "Variables and Data Types\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\nboolean_variable = True\nnothing_variable = None\n\nfloat_variable\n\n10.5"
  },
  {
    "objectID": "python_basics.html#control-structures",
    "href": "python_basics.html#control-structures",
    "title": "Introduction to Python",
    "section": "Control Structures",
    "text": "Control Structures\nPython supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "python_basics.html#functions",
    "href": "python_basics.html#functions",
    "title": "Introduction to Python",
    "section": "Functions",
    "text": "Functions\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "python_basics.html#lists-and-dictionaries",
    "href": "python_basics.html#lists-and-dictionaries",
    "title": "Introduction to Python",
    "section": "Lists and Dictionaries",
    "text": "Lists and Dictionaries\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\nA tuple is a collection which is immutable.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}\n\n# Tuple example:\nmy_tuple = (1, 2, 3)\n\n\n# for Loops\n\nA loop is a way of executing a piece of code over and over\n\nname_list = [\"Ben\", \"Chris\", \"Kate\", \"Mary\"]\n\nfor name in name_list:\n    print(name)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/python-basics/python-basics.html",
    "href": "posts/python-basics/python-basics.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language."
  },
  {
    "objectID": "posts/python-basics/python-basics.html#what-is-python",
    "href": "posts/python-basics/python-basics.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language."
  },
  {
    "objectID": "posts/python-basics/python-basics.html#variables-and-data-types",
    "href": "posts/python-basics/python-basics.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "Variables and Data Types",
    "text": "Variables and Data Types\nVariables can store data of different types. There are many different data types.\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\nboolean_variable = True\nnothing_variable = None"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#control-structures",
    "href": "posts/python-basics/python-basics.html#control-structures",
    "title": "Python Basics",
    "section": "Control Structures",
    "text": "Control Structures\nPython supports basic conditions from math:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#lists-dictionaries-and-tuples",
    "href": "posts/python-basics/python-basics.html#lists-dictionaries-and-tuples",
    "title": "Python Basics",
    "section": "Lists, Dictionaries, and Tuples",
    "text": "Lists, Dictionaries, and Tuples\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\nA tuple is a collection which is immutable.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}\n\n# Tuple example:\nmy_tuple = (1, 2, 3)"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#for-loops",
    "href": "posts/python-basics/python-basics.html#for-loops",
    "title": "Python Basics",
    "section": "for Loops",
    "text": "for Loops\nA loop is a way of executing a piece of code over and over\n\nname_list = [\"Ben\", \"Chris\", \"Kate\", \"Mary\"]\n\nfor name in name_list:\n    print(name)\n\nBen\nChris\nKate\nMary"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#slicing-methods",
    "href": "posts/python-basics/python-basics.html#slicing-methods",
    "title": "Python Basics",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nAn index is the position of a specific element in a sequence. Indexing in Python starts with 0.\nSlicing is a way to get a subset of a data object.\nYou can slice by using square brackets [], a start index, and an end index. You can also incude a ‚Äústep‚Äù count to determine how you want to skip position by.\nformat: [start : end : step]\n\nstring = \"abcdefghijklmnaop\"\nprint( string[1 : 6 : 2] )\n\nbdf"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#importing-modules-packages-and-libraries",
    "href": "posts/python-basics/python-basics.html#importing-modules-packages-and-libraries",
    "title": "Python Basics",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nA module is a group of related codes saved in a file with the extension .py\nA package is a directory of a collection of modules\nA library is a collection of packages\nYou can import modules, open Anaconda Prompt or Terminal and run:\n\npip install module_name\n\nRequirement already satisfied: module_name in c:\\users\\15857\\anaconda3\\lib\\site-packages (0.6.0)Note: you may need to restart the kernel to use updated packages.\n\n\n\nTo install a module on Google Colab add a excalamation point ! in the beginning"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let‚Äôs analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe‚Äôll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI‚Äôll begin with these analyses and create visualizations to help us understand the data better. Let‚Äôs start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let‚Äôs calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there‚Äôs a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nggplot Basics\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nNada Trabelsi\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nNada Trabelsi\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\nFeb 20, 2024\n\n\nNada Trabelsi\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nada Trabelsi",
    "section": "",
    "text": "Nada Trabelsi majors in Accounting with a minor in Data Analytics at SUNY Geneseo. When not working at her family restaurant, Nada enjoys spending time crocheting and learning how to sew."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Nada Trabelsi",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Accounting | Aug 2022 - May 2026  Minor in Data Analytics"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Nada Trabelsi",
    "section": "Experience",
    "text": "Experience\nGregorio‚Äôs Pizzeria | Part-Time Restaurant Worker | June 2018 - Present\nSewgreen | Sewing Supply Store Intern | July 2022-Aug 2022"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code with no space in the folder name.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let‚Äôs analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs.¬†Droid",
    "text": "Human vs.¬†Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Understanding ESG Metrics and Financial Anaylis By Sector",
    "section": "",
    "text": "1 Introduction\nESG metrics are performance indicators of a company‚Äôs performance on Environmental, Social, and Governance issues. The ESG risk rating measures a companies risk of mismanaging environmental, social, and governance issues. A companies Controversy Level measures the level of incidents that negatively impact stockholders, the environment, or operations. A level 5 shows the highest controversy level with incidents that have the greatest possible impact to the company.\nI will be taking a deeper look and comparing companies ESG risk scores and financial analysis. Specifically focusing on the varying sectors and if there is a connection between a companies controversy level and their financials.\nFirst, I will merge the dataframes with the variables I will be using into one single DataFrame, ‚Äòdf‚Äô.\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nesg_proj = pd.read_csv(\"https://bcdanl.github.io/data/esg_proj.csv\")\nhistory= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_history.csv')\ninc_stmnt= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_income_stmt.csv')\nbal_sheet= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_balance_sheet.csv')\nesg_scores = pd.read_csv(\"https://ntrabelsi109.github.io/project_files/company_esg_scores.csv\")\n\n#Create merged dataframe with variables I will be using\ndf1= (\n      esg_proj\n      [['Symbol', 'Company Name', 'Sector', 'Industry']]\n      )\ndf2= (\n      inc_stmnt\n      [['date', 'company_name','Net Income', 'Total Expenses', 'Gross Profit', 'Total Revenue']]\n      .rename(columns={'company_name': 'Symbol'})\n      )\ndf3= (\n      bal_sheet\n      [['date', 'company_name', 'Total Assets', 'Stockholders Equity', 'Common Stock','Net Debt']]\n      .rename(columns={'company_name': 'Symbol'})\n      )\ndf4=(\n     esg_scores\n     .rename(columns={'company':'Symbol'}))\n\n\ndf= pd.merge(esg_proj,df2, on='Symbol')\ndf=pd.merge(df, df3, on=['Symbol', 'date'])\ndf=pd.merge(df, df4, on=['Symbol'])\ndf.nunique()\n\n\nSymbol                  634\nCompany Name            633\nSector                   12\nIndustry                123\nCountry                  19\nMarket Cap              634\ndate                     14\nNet Income             2569\nTotal Expenses         2744\nGross Profit           2476\nTotal Revenue          2956\nTotal Assets           3047\nStockholders Equity    3021\nCommon Stock           1302\nNet Debt               2611\nenv_score               177\nsoc_score               155\ngov_score               108\ntotal_score             250\ncontroversy_lvl           5\ndtype: int64\n\n\n\n\n2 The Distribution of ESG Scores\n\n\nCode\nsns.histplot(df,\n              x= 'total_score',\n              bins= 10,\n             hue= 'Sector')\n\n\n&lt;Axes: xlabel='total_score', ylabel='Count'&gt;\n\n\n\n\n\n\n\nCode\nsns.countplot(df,\n              x= 'controversy_lvl')\n\n\n&lt;Axes: xlabel='controversy_lvl', ylabel='count'&gt;\n\n\n\n\n\n\n\nCode\ndf.groupby('Sector')['controversy_lvl'].describe()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nSector\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Materials\n35.0\n3.000000\n0.766965\n2.0\n2.0\n3.0\n4.0\n4.0\n\n\nCommunication Services\n70.0\n2.157143\n0.651324\n1.0\n2.0\n2.0\n3.0\n3.0\n\n\nConsumer Discretionary\n697.0\n1.984218\n0.659618\n1.0\n2.0\n2.0\n2.0\n4.0\n\n\nConsumer Staples\n99.0\n2.626263\n0.581796\n2.0\n2.0\n3.0\n3.0\n4.0\n\n\nEnergy\n123.0\n2.040650\n0.717445\n1.0\n2.0\n2.0\n3.0\n3.0\n\n\nFinancial Services\n440.0\n1.836364\n0.829713\n1.0\n1.0\n2.0\n2.0\n5.0\n\n\nHealth Care\n278.0\n2.248201\n0.853690\n1.0\n2.0\n2.0\n3.0\n5.0\n\n\nIndustrials\n390.0\n1.943590\n0.766857\n1.0\n1.0\n2.0\n2.0\n4.0\n\n\nMiscellaneous\n4.0\n2.000000\n0.000000\n2.0\n2.0\n2.0\n2.0\n2.0\n\n\nReal Estate\n122.0\n1.196721\n0.399159\n1.0\n1.0\n1.0\n1.0\n2.0\n\n\nTechnology\n258.0\n1.806202\n0.818821\n1.0\n1.0\n2.0\n2.0\n4.0\n\n\nUtilities\n185.0\n2.081081\n0.852693\n1.0\n2.0\n2.0\n2.0\n5.0\n\n\n\n\n\n\n\nBy looking at the distribution of ESG metrics, we can see that a majority of companies have a total risk score around 10-30. With the sectors with the highest risk score above 40 being Energy, and Utilities.\nThe average company has a controversy level of 2, with only a few companies having a controversy level above 5.Only three sectors have companies who reached a level of 5: Financial Services, Health Care, and Utilities. However, the sector who has the greatest average and median is Basic Materials and the sector with the lowest controversy level is Real Estate with at least 75% of the companies only having a controversy level of 1 and the highest controversy level being 2.\n\n\n3 Financials By Sector\n\n\nCode\nsectors_gp= (\n    df\n    .groupby('Sector')\n    ['Gross Profit']\n)\nsectors_gp.describe()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nSector\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Materials\n39.0\n8.723186e+08\n5.478340e+08\n1.175010e+08\n5.102820e+08\n8.310000e+08\n1.249500e+09\n1.956000e+09\n\n\nCommunication Services\n60.0\n8.202911e+09\n7.484955e+09\n5.402410e+08\n1.888500e+09\n4.234000e+09\n1.383225e+10\n2.166400e+10\n\n\nConsumer Discretionary\n712.0\n2.143730e+09\n3.982030e+09\n-1.200000e+07\n5.627092e+08\n9.928395e+08\n2.135057e+09\n4.156300e+10\n\n\nConsumer Staples\n104.0\n3.071622e+09\n3.780767e+09\n3.970000e+08\n8.153500e+08\n1.264200e+09\n3.452000e+09\n1.475300e+10\n\n\nEnergy\n142.0\n3.137069e+09\n4.435765e+09\n-1.195190e+08\n6.852500e+08\n1.799500e+09\n3.846500e+09\n2.396100e+10\n\n\nFinancial Services\n107.0\n1.001935e+09\n6.714125e+08\n7.914100e+07\n4.761500e+08\n8.120000e+08\n1.439500e+09\n3.003000e+09\n\n\nHealth Care\n268.0\n3.349850e+09\n4.379822e+09\n9.487800e+07\n6.529835e+08\n1.515500e+09\n4.034000e+09\n2.338800e+10\n\n\nIndustrials\n472.0\n1.076500e+09\n1.088400e+09\n-7.040520e+08\n3.923628e+08\n6.717000e+08\n1.462425e+09\n6.428000e+09\n\n\nMiscellaneous\n4.0\n8.092500e+08\n3.536716e+08\n5.960000e+08\n6.155000e+08\n6.520000e+08\n8.457500e+08\n1.337000e+09\n\n\nReal Estate\n190.0\n5.109807e+08\n4.256441e+08\n2.676400e+07\n2.149412e+08\n3.859300e+08\n7.176070e+08\n2.045800e+09\n\n\nTechnology\n349.0\n4.168420e+09\n9.194252e+09\n-1.206000e+09\n5.572000e+08\n1.113822e+09\n2.559000e+09\n5.485500e+10\n\n\nUtilities\n203.0\n1.458809e+09\n9.803909e+08\n-1.056000e+09\n8.093500e+08\n1.224575e+09\n1.970000e+09\n8.108000e+09\n\n\n\n\n\n\n\n\n\nCode\n(\n sns.FacetGrid(\n       data = df,\n       row='Sector')\n .map(sns.histplot, 'Stockholders Equity')\n )\n\n\n\n\n\nThe Sector with the highest average gross profit is Communication Services, the lowest being Real Estate. When looking at stockholders equity, most sectors are concentrated around the same area with a few sectors have a wider distribution particularly Financial Services.\n\n\n4 Unifying ESG Metrics and Financials\n\n\nCode\ncorr = df[['Gross Profit', 'Market Cap', 'Stockholders Equity', 'env_score', 'soc_score', 'gov_score', 'controversy_lvl']].corr()\n\nplt.figure(figsize=(8, 6))\n\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\nplt.title('Correlation Between Financials and ESG Scores')\n\n\nText(0.5, 1.0, 'Correlation Between Financials and ESG Scores')\n\n\n\n\n\nMarket capitalization and Stockholders equity shave a strong, positive correlation with a companies gross profit. However there does not appear to be any strong correlation between a companies financials and their ESG score or controversy level. The highest correlation is the controversy level and gross profit at a weak, positive correlation of .38.\n\n\n5 Diving Deeper into ESG Metrics\n\nWhat is the top industry for each sector that has the highest environmental risk score?\n\n\n\nCode\nsectors_top_industry_env= (\n    df\n    .sort_values('env_score', ascending=False)\n    .groupby('Sector')\n    .head(1)\n)\nsectors_top_industry_env\nsns.barplot(sectors_top_industry_env,\n    x='env_score',\n    y='Industry',\n    hue= 'Sector'\n)\n\n\n&lt;Axes: xlabel='env_score', ylabel='Industry'&gt;\n\n\n\n\n\n\nWhich industry within each sector has the highest controversy levels?\n\n\n\nCode\nsectors_top_industry_cont= (\n    df\n    .sort_values('controversy_lvl', ascending=False)\n    .groupby('Sector')\n    .head(1)\n)\nsns.barplot(sectors_top_industry_cont,\n    x='controversy_lvl',\n    y='Industry',\n    hue= 'Sector'\n)\n\n\n&lt;Axes: xlabel='controversy_lvl', ylabel='Industry'&gt;\n\n\n\n\n\nWhile a company‚Äôs ESG score or controversy level might not have a strong correlation with a company‚Äôs financials, investors should still take into consideration the ESG risk scores and controversy level that might bring potential harm to the company. Considering ESG risk and controversy levels can allow investors to consider the sustainability of a certain company and will help them make more informed decisions.\n\n\n6 References\n‚ÄúA Guide to Understanding ESG Ratings.‚Äù Yahoo! Finance, Yahoo!, finance.yahoo.com/news/guide-understanding-esg-ratings-151501443.html.\nI collaborated with Jordan Alfano to create the code used for collecting data using the yfinance API and web scraping with Selenium.\nChatGPT was used to generate the lines of code that allowed the webdriver to launch and quit after pocessing every 20 companies."
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nmpg &lt;- ggplot2::mpg\n\n\n\n\n  \n\n\n\nskim(mpg) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n1\n4\n10\n0\n15\n0\n\n\nmodel\n1\n2\n22\n0\n38\n0\n\n\ntrans\n1\n8\n10\n0\n10\n0\n\n\ndrv\n1\n1\n1\n0\n3\n0\n\n\nfl\n1\n1\n1\n0\n5\n0\n\n\nclass\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ\n\n\nyear\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñá\n\n\ncyl\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\ncty\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ\n\n\nhwy\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL Project",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) üöô üöö üöê.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "posts/python-basics/python-basics.html#practice-problems",
    "href": "posts/python-basics/python-basics.html#practice-problems",
    "title": "Python Basics",
    "section": "Practice Problems",
    "text": "Practice Problems\nQuestion 1.\nUsing Python operations only, calculate below:\n\n2**5/(7*(4-2**3))\n\n-1.1428571428571428\n\n\nQuestion 2.\nFor each expression below, what is the value of the expression? Explain thoroughly.\n\n20 == '20'\n\nFalse\n\n\nFalse, because the integer 20 is not equal to the string 20.\n\nx = 4.0\ny = .5\nz = 3*y - x\n\nx &lt; y or 3*y &lt; x\n\nTrue\n\n\nTrue because by using ‚Äúor‚Äù you only need one of the statements to be true. So although one is false, because the other is true, the whole expression is true.\nQuestion 3.\nWrite a Python code that uses slicing and the print() function to print out the following message:\nThe total trip cost is: $12.80\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\n\ntotal= fare[1] + tip[0] + \".\" + tax[4:6]\nprint(\"The total trip is: $\" + total)\n\nThe total trip is: $12.80\n\n\nQuestion 4.\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\nThe largest value in the list is: 1000\n\nlist_variable = [100, 144, 169, 1000, 8]\nprint(\"The largest value in the list is: \", max(list_variable))\n\nThe largest value in the list is:  1000\n\n\nQuestion 5.\nImport the pandas library as pd. Install the itables package. From itables, import the functions init_notebook_mode and show.\n\nimport pandas as pd\n!pip install itables\nfrom itables import init_notebook_mode\nfrom itables import show\n\nRequirement already satisfied: itables in c:\\users\\15857\\anaconda3\\lib\\site-packages (1.7.0)\nRequirement already satisfied: IPython in c:\\users\\15857\\anaconda3\\lib\\site-packages (from itables) (8.15.0)\nRequirement already satisfied: pandas in c:\\users\\15857\\anaconda3\\lib\\site-packages (from itables) (2.0.3)\nRequirement already satisfied: numpy in c:\\users\\15857\\anaconda3\\lib\\site-packages (from itables) (1.24.3)\nRequirement already satisfied: backcall in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: decorator in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.18.1)\nRequirement already satisfied: matplotlib-inline in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.1.6)\nRequirement already satisfied: pickleshare in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (3.0.36)\nRequirement already satisfied: pygments&gt;=2.4.0 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (2.15.1)\nRequirement already satisfied: stack-data in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: traitlets&gt;=5 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (5.7.1)\nRequirement already satisfied: colorama in c:\\users\\15857\\anaconda3\\lib\\site-packages (from IPython-&gt;itables) (0.4.6)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from pandas-&gt;itables) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from pandas-&gt;itables) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from pandas-&gt;itables) (2023.3)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from jedi&gt;=0.16-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: wcwidth in c:\\users\\15857\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30-&gt;IPython-&gt;itables) (0.2.5)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\15857\\anaconda3\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;itables) (1.16.0)\nRequirement already satisfied: executing in c:\\users\\15857\\anaconda3\\lib\\site-packages (from stack-data-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: asttokens in c:\\users\\15857\\anaconda3\\lib\\site-packages (from stack-data-&gt;IPython-&gt;itables) (2.0.5)\nRequirement already satisfied: pure-eval in c:\\users\\15857\\anaconda3\\lib\\site-packages (from stack-data-&gt;IPython-&gt;itables) (0.2.2)"
  },
  {
    "objectID": "posts/spotify/spotify.html",
    "href": "posts/spotify/spotify.html",
    "title": "Spotify",
    "section": "",
    "text": "import pandas as pd\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\nspotify.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 198005 entries, 0 to 198004\nData columns (total 7 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   pid            198005 non-null  int64 \n 1   playlist_name  198005 non-null  object\n 2   pos            198005 non-null  int64 \n 3   artist_name    198005 non-null  object\n 4   track_name     198005 non-null  object\n 5   duration_ms    198005 non-null  int64 \n 6   album_name     198005 non-null  object\ndtypes: int64(3), object(4)\nmemory usage: 10.6+ MB"
  },
  {
    "objectID": "posts/spotify/spotify.html#loading-the-dataset",
    "href": "posts/spotify/spotify.html#loading-the-dataset",
    "title": "Spotify",
    "section": "",
    "text": "import pandas as pd\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\nspotify.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 198005 entries, 0 to 198004\nData columns (total 7 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   pid            198005 non-null  int64 \n 1   playlist_name  198005 non-null  object\n 2   pos            198005 non-null  int64 \n 3   artist_name    198005 non-null  object\n 4   track_name     198005 non-null  object\n 5   duration_ms    198005 non-null  int64 \n 6   album_name     198005 non-null  object\ndtypes: int64(3), object(4)\nmemory usage: 10.6+ MB"
  },
  {
    "objectID": "posts/spotify/spotify.html#variable-description",
    "href": "posts/spotify/spotify.html#variable-description",
    "title": "Spotify",
    "section": "Variable Description",
    "text": "Variable Description\n\npid: playlist ID; unique ID for playlist\nplaylist_name: a name of playlist\npos: a position of the track within a playlist (starting from 0)\nartist_name: name of the track‚Äôs primary artist\ntrack_name: name of the track\nduration_ms: duration of the track in milliseconds\nalbum_name: name of the track‚Äôs album"
  },
  {
    "objectID": "posts/spotify/spotify.html#filtering",
    "href": "posts/spotify/spotify.html#filtering",
    "title": "Spotify",
    "section": "Filtering",
    "text": "Filtering\nI will filter for one of my favorite artists: Shakira.\n\nshakira = spotify[ spotify[\"artist_name\"] == \"Shakira\"]\nshakira\n\n\n\n\n\n\n\n\npid\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\n\n\n4357\n72\nspanish jams\n100\nShakira\nLa Tortura\n212893\nFijacion Oral\n\n\n6504\n105\n~Rando~\n70\nShakira\nHips Don't Lie\n218093\nOral Fixation Vol. 2\n\n\n7021\n112\n4/20\n38\nShakira\nOjos As√≠\n237533\nGrandes Exitos\n\n\n7139\n115\nbeach\n49\nShakira\nHips Don't Lie\n218093\nOral Fixation Vol. 2\n\n\n7724\n123\nw o r k o u t\n63\nShakira\nHips Don't Lie\n218093\nOral Fixation Vol. 2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n197628\n999992\nGB\n14\nShakira\nLo Hecho Est√° Hecho\n192693\nShe Wolf (Deluxe Version)\n\n\n197629\n999992\nGB\n15\nShakira\nLa Tortura\n212893\nFijacion Oral\n\n\n197664\n999992\nGB\n50\nShakira\nWhenever, Wherever\n196160\nLaundry Service (Alben f√ºr die Ewigkeit)\n\n\n197665\n999992\nGB\n51\nShakira\nLa La La\n186333\nShakira. (Deluxe Version)\n\n\n197666\n999992\nGB\n52\nShakira\nNunca Me Acuerdo de Olvidarte\n206466\nShakira. (Deluxe Version)\n\n\n\n\n174 rows √ó 7 columns"
  },
  {
    "objectID": "posts/spotify/spotify.html#indexing-and-sorting",
    "href": "posts/spotify/spotify.html#indexing-and-sorting",
    "title": "Spotify",
    "section": "Indexing and Sorting",
    "text": "Indexing and Sorting\n\nshakira= (\n          shakira\n          .set_index(\"pid\")\n          .sort_index(ascending=True)\n)\nshakira.sort_values(by = [\"playlist_name\", \"pos\"],\n                    ascending = True)\n\n\n\n\n\n\n\n\nplaylist_name\npos\nartist_name\ntrack_name\nduration_ms\nalbum_name\n\n\npid\n\n\n\n\n\n\n\n\n\n\n999448\n#tb\n26\nShakira\nHips Don't Lie\n218093\nOral Fixation Vol. 2\n\n\n779\n00s\n23\nShakira\nWhenever, Wherever\n196160\nLaundry Service (Alben f√ºr die Ewigkeit)\n\n\n779\n00s\n47\nShakira\nUnderneath Your Clothes\n224066\nLaundry Service (Alben f√ºr die Ewigkeit)\n\n\n663\n2000s hits\n28\nShakira\nHips Don't Lie\n218093\nOral Fixation Vol. 2\n\n\n112\n4/20\n38\nShakira\nOjos As√≠\n237533\nGrandes Exitos\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n506\nüíÉüèΩ\n39\nShakira\nLa Tortura\n212893\nFijacion Oral\n\n\n506\nüíÉüèΩ\n40\nShakira\nWhenever, Wherever\n196160\nLaundry Service (Alben f√ºr die Ewigkeit)\n\n\n506\nüíÉüèΩ\n41\nShakira\nLoca\n183693\nSale El Sol\n\n\n506\nüíÉüèΩ\n42\nShakira\nGordita\n204986\nSale El Sol\n\n\n506\nüíÉüèΩ\n43\nShakira\nAddicted to You\n147480\nSale El Sol\n\n\n\n\n174 rows √ó 6 columns"
  },
  {
    "objectID": "posts/spotify/spotify.html#counting",
    "href": "posts/spotify/spotify.html#counting",
    "title": "Spotify",
    "section": "Counting",
    "text": "Counting\n\nshakira.nunique()\n\nplaylist_name    116\npos               86\nartist_name        1\ntrack_name        35\nduration_ms       36\nalbum_name        12\ndtype: int64\n\n\nThere are 116 unique playlists that have atleast 1 Shakira song in it.\n\nshakira['playlist_name'].value_counts()\n\nplaylist_name\nüíÉüèΩ              9\nmusica          7\nspanish jams    6\nGB              6\nParty           4\n               ..\nTaylor swift    1\nGabriel         1\nweekend         1\nmisc.           1\neverything      1\nName: count, Length: 116, dtype: int64\n\n\nThe playlist with the most Shakira songs is ‚ÄúüíÉ‚Äù with 9 songs included.\n\nshakira[\"track_name\"].value_counts()\n\ntrack_name\nHips Don't Lie                                                                   53\nChantaje                                                                         18\nLa Tortura                                                                       13\nWaka Waka (This Time for Africa) (The Official 2010 FIFA World Cup (TM) Song)    12\nTry Everything - From \"Zootropolis\"                                               9\nCan't Remember to Forget You                                                      9\nWhenever, Wherever                                                                8\nMe Enamor√©                                                                        7\nRabiosa                                                                           5\nPerro Fiel                                                                        4\nLoca                                                                              4\nAddicted to You                                                                   4\nOjos As√≠                                                                          2\nTrap                                                                              2\nUnderneath Your Clothes                                                           2\nShe Wolf                                                                          2\nGordita                                                                           2\nTe Aviso, Te Anuncio (Tango)                                                      1\nEmpire                                                                            1\nLo Hecho Est√° Hecho                                                               1\nEyes Like Yours (Ojos As√≠)                                                        1\nLa La La                                                                          1\nSuerte (Whenever, Wherever)                                                       1\nYou Don't Care About Me                                                           1\nLoca por Ti                                                                       1\nSombra de Ti                                                                      1\nCiega, Sordomuda                                                                  1\nAntologia                                                                         1\nMoscas en la Casa                                                                 1\nPienso en Ti                                                                      1\nDare (La La La)                                                                   1\nNo                                                                                1\nGypsy                                                                             1\nDon't Bother                                                                      1\nNunca Me Acuerdo de Olvidarte                                                     1\nName: count, dtype: int64\n\n\nThe most popular song (added to playlist the most times) is ‚ÄúHips Don‚Äôt Lie‚Äù."
  },
  {
    "objectID": "project_possibly.html",
    "href": "project_possibly.html",
    "title": "Project?",
    "section": "",
    "text": "import seaborn as sns import numpy as np from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.chrome.options import Options import time"
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Understanding ESG Metrics and Financial Anaylis By Sector",
    "section": "",
    "text": "ESG metrics are performance indicators of a company‚Äôs performance on Environmental, Social, and Governance issues. The ESG risk rating measures a companies risk of mismanaging environmental, social, and governance issues. A companies Controversy Level measures the level of incidents that negatively impact stockholders, the environment, or operations. A level 5 shows the highest controversy level with incidents that have the greatest possible impact to the company.\nI will be taking a deeper look and comparing companies ESG risk scores and financial analysis. Specifically focusing on the varying sectors and if there is a connection between a companies controversy level and their financials.\nFirst, I will merge the dataframes with the variables I will be using into one single DataFrame, ‚Äòdf‚Äô.\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nesg_proj = pd.read_csv(\"https://bcdanl.github.io/data/esg_proj.csv\")\nhistory= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_history.csv')\ninc_stmnt= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_income_stmt.csv')\nbal_sheet= pd.read_csv('https://ntrabelsi109.github.io/project_files/yfinance_balance_sheet.csv')\nesg_scores = pd.read_csv(\"https://ntrabelsi109.github.io/project_files/company_esg_scores.csv\")\n\n#Create merged dataframe with variables I will be using\ndf1= (\n      esg_proj\n      [['Symbol', 'Company Name', 'Sector', 'Industry']]\n      )\ndf2= (\n      inc_stmnt\n      [['date', 'company_name','Net Income', 'Total Expenses', 'Gross Profit', 'Total Revenue']]\n      .rename(columns={'company_name': 'Symbol'})\n      )\ndf3= (\n      bal_sheet\n      [['date', 'company_name', 'Total Assets', 'Stockholders Equity', 'Common Stock','Net Debt']]\n      .rename(columns={'company_name': 'Symbol'})\n      )\ndf4=(\n     esg_scores\n     .rename(columns={'company':'Symbol'}))\n\n\ndf= pd.merge(esg_proj,df2, on='Symbol')\ndf=pd.merge(df, df3, on=['Symbol', 'date'])\ndf=pd.merge(df, df4, on=['Symbol'])\ndf.nunique()\n\n\nSymbol                  634\nCompany Name            633\nSector                   12\nIndustry                123\nCountry                  19\nMarket Cap              634\ndate                     14\nNet Income             2569\nTotal Expenses         2744\nGross Profit           2476\nTotal Revenue          2956\nTotal Assets           3047\nStockholders Equity    3021\nCommon Stock           1302\nNet Debt               2611\nenv_score               177\nsoc_score               155\ngov_score               108\ntotal_score             250\ncontroversy_lvl           5\ndtype: int64"
  },
  {
    "objectID": "lecture3.html",
    "href": "lecture3.html",
    "title": "Lecture 3",
    "section": "",
    "text": "Code\nlibrary(skimr)\nlibrary(gapminder)\ngapminder\n\n\n# A tibble: 1,704 √ó 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ‚Ñπ 1,694 more rows\n\n\nCode\nskim(gapminder)\n\n\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n1704\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ncountry\n0\n1\nFALSE\n142\nAfg: 12, Alb: 12, Alg: 12, Ang: 12\n\n\ncontinent\n0\n1\nFALSE\n5\nAfr: 624, Asi: 396, Eur: 360, Ame: 300\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1979.50\n17.27\n1952.00\n1965.75\n1979.50\n1993.25\n2007.0\n‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá\n\n\nlifeExp\n0\n1\n59.47\n12.92\n23.60\n48.20\n60.71\n70.85\n82.6\n‚ñÅ‚ñÜ‚ñá‚ñá‚ñá\n\n\npop\n0\n1\n29601212.32\n106157896.74\n60011.00\n2793664.00\n7023595.50\n19585221.75\n1318683096.0\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\ngdpPercap\n0\n1\n7215.33\n9857.45\n241.17\n1202.06\n3531.85\n9325.46\n113523.1\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\np &lt;- ggplot(data = gapminder)\np &lt;- ggplot(data = gapminder,\n            mapping = aes(x = gdpPercap,\n                          y = lifeExp))\n\n\n\n\nCode\np + geom_point() \n\n\n\n\n\n\n\n\n\n\n\nCode\np + geom_point() + geom_smooth() \n\n\n\n\n\n\n\n\n\nCode\np + geom_point() + geom_smooth(method = \"lm\") \n\n\n\n\n\n\n\n\n\nCode\np + geom_point() +\n    geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data = gapminder,\n            mapping = aes(x = gdpPercap,\n                          y = lifeExp))\n\np + geom_point(color = \"purple\") +\n    geom_smooth(method = \"loess\") \n\n\n\n\n\n\n\n\n\nCode\np + geom_point(alpha = 0.3) +\n    geom_smooth(color = \"orange\", \n                se = F, \n                size = 8, \n                method = lm) \n\n\n\n\n\n\n\n\n\n\n\nCode\np + geom_point(alpha = 0.3) +\n    geom_smooth(method = \"gam\") +\n    scale_x_log10(labels = scales::dollar) +\n    labs(x = \"GDP Per Capita\", y = \"Life Expectancy in Years\",\n         title = \"Economic Growth and Life Expectancy\",\n         subtitle = \"Data points are country-years\",\n         caption = \"Source: Gapminder.\")\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data = gapminder, \n            mapping = aes(x = gdpPercap, y = lifeExp))\n\np + geom_point(mapping = aes(color = continent)) +\n    geom_smooth(method = \"loess\")  +\n    scale_x_continuous(trans = scales::log_trans())  # natural log"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html",
    "href": "posts/ggplot-basics/ggplot_basics.html",
    "title": "ggplot Basics",
    "section": "",
    "text": "#Load libraries\nlibrary(tidyverse)\nlibrary(ggthemes)\n\n#set theme\n\ntheme_set(theme_minimal())\n\n\n\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy, \n                   color = class,\n                   shape = class) )\n\n\n\n\n\n\n\n\n\n\n\nAdding transparency and changing size can help with issues of overplotting.\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             alpha = .2)\n\n\n\n\n\n\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             size = 3)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#color-and-shape",
    "href": "posts/ggplot-basics/ggplot_basics.html#color-and-shape",
    "title": "ggplot Basics",
    "section": "",
    "text": "ggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy, \n                   color = class) )\n\n\n\n\n\n\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy, \n                   color = class) )"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#setting-transparency-and-size",
    "href": "posts/ggplot-basics/ggplot_basics.html#setting-transparency-and-size",
    "title": "ggplot Basics",
    "section": "",
    "text": "Adding transparency and changing size can help with issues of overplotting.\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             alpha = .2)\n\n\n\n\n\n\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             size = 3)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#scatterplot",
    "href": "posts/ggplot-basics/ggplot_basics.html#scatterplot",
    "title": "ggplot Basics",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy),\n             alpha = .3)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#setting-color-and-shape",
    "href": "posts/ggplot-basics/ggplot_basics.html#setting-color-and-shape",
    "title": "ggplot Basics",
    "section": "",
    "text": "ggplot(data = mpg) + \n  geom_point(mapping = \n               aes(x = displ, \n                   y = hwy, \n                   color = class,\n                   shape = class) )"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#fitted-lines",
    "href": "posts/ggplot-basics/ggplot_basics.html#fitted-lines",
    "title": "ggplot Basics",
    "section": "Fitted Lines",
    "text": "Fitted Lines\nWe can set the linetype of the fitted line with linetype()\n\nggplot( data = mpg ) + \n  geom_smooth( mapping = \n                 aes( x = displ, \n                      y = hwy, \n                      linetype = drv) )\n\n\n\n\n\n\n\n\nYou can get a linear fitted line by setting method = lm.\nThe grey shaded area is the standard error. It can be removed by setting se = False (or F)\n\nggplot( data = mpg ) + \n  geom_smooth( mapping = \n                 aes( x = displ, \n                      y = hwy),\n               method = lm,\n               se = F)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#histogram",
    "href": "posts/ggplot-basics/ggplot_basics.html#histogram",
    "title": "ggplot Basics",
    "section": "Histogram",
    "text": "Histogram\nHistograms can be used to plot continuous variables like a bar chart.\nNumber of bins or the width of the bars can be set with ‚Äúbins =‚Äù and ‚Äúbinwidth =‚Äù, respectively.\n\nggplot(diamonds) +\n  geom_histogram(aes(x = price), \n                 bins = 100)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#frequency-polygon",
    "href": "posts/ggplot-basics/ggplot_basics.html#frequency-polygon",
    "title": "ggplot Basics",
    "section": "Frequency Polygon",
    "text": "Frequency Polygon\nA frequency polygon is a line version of a histogram.\n\nggplot(diamonds) +\n  geom_freqpoly(aes(x = price), \n                 bins = 100)"
  },
  {
    "objectID": "posts/ggplot-basics/ggplot_basics.html#combining-geom-objects",
    "href": "posts/ggplot-basics/ggplot_basics.html#combining-geom-objects",
    "title": "ggplot Basics",
    "section": "Combining Geom Objects",
    "text": "Combining Geom Objects\n\nlibrary(gapminder)\ngapminder &lt;- gapminder\np &lt;- ggplot(data = gapminder,\n            mapping = aes(x = gdpPercap,\n                          y = lifeExp))\np_out &lt;- p + geom_point(aes(color = continent)) + geom_smooth(se = F) \np_out"
  }
]